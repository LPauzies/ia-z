
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Généralisation d’un modèle de Machine Learning &#8212; IA-Z</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Régularisation &amp; tradeoff biais-variance : une introduction" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html" />
    <link rel="prev" title="Introduction à la régression : la régression linéaire" href="03%20-%20Regression%20lineaire.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IA-Z</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../README.html">
   Sommaire
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage automatique
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="01%20-%20Pourquoi%20le%20ML%20%26%20information%20gr%C3%A2ce%20%C3%A0%20la%20data.html">
   Pourquoi le Machine Learning ?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="02%20-%20Elements%20de%20definition.html">
     Eléments de définition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03%20-%20Regression%20lineaire.html">
     Introduction à la régression : la régression linéaire
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Généralisation d’un modèle de Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html">
     Régularisation &amp; tradeoff biais-variance : une introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07%20-%20R%C3%A9gularisation%20d%27un%20mod%C3%A8le.html">
     Régularisation d’un modèle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08%20-%20Compromis%20biais-variance.html">
     Compromis biais-variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11%20-%20Feature%20engineering%20%26%20cleaning.html">
     Feature Engineering
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Traitement automatique de la langue
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../NLP/chapitre1_introduction/1_Introduction.html">
   Chapitre I: Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre1_introduction/2_DonneesTextuelles.html">
     Etude des données textuelles
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/3_ModStatLangage.html">
   Chapitre II: Notions générales
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/4_ModLangues.html">
     Modèles de langues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../NLP/chapitre2_notionsgenerales/5_Embedings.html">
     Embeddings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision par ordinateur
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/0_intro.html">
   Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/1_Image_processing.html">
   Section 1 Image processing techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/2_ML_CV.html">
   Machine Learning for Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/3_CNN.html">
   Convolutional Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/4_Modern_CNN.html">
   Modern Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/5_CV_tasks.html">
   Computer Vision tasks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage par renforcement
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20RL/1%20-%20Introduction.html">
   Introduction au Reinforcement learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20RL/3%20-%20Processus%20de%20d%C3%A9cision%20markoviens.html">
   Processus de décision markoviens (MDPs)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hors-série
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20annexes/mener_une_recherche.html">
   Mener une recherche internet efficacement
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/docs/Cours fondamentaux ML/module_1_introduction/05 - Generalisation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ia-z/ia-z"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ia-z/ia-z/issues/new?title=Issue%20on%20page%20%2Fdocs/Cours fondamentaux ML/module_1_introduction/05 - Generalisation.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ia-z/ia-z/master?urlpath=tree/docs/Cours fondamentaux ML/module_1_introduction/05 - Generalisation.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#le-besoin-de-generaliser">
   Le besoin de généraliser
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definitions">
   Définitions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting">
     Overfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#underfitting">
     Underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalisation-d-un-modele">
     Généralisation d’un modèle
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exemples">
   Exemples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Overfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalisation">
     Généralisation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluer-la-generalisation-d-un-modele">
   Évaluer la généralisation d’un modèle
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test">
     Train/Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#la-recherche-d-hyperparametres">
   La recherche d’hyperparamètres
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-val-test">
     Train/Val/Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#retour-sur-l-exemple-une-bonne-facon-de-faire">
   Retour sur l’exemple : une bonne façon de faire
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#details-supplementaires">
   Détails supplémentaires
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Généralisation d’un modèle de Machine Learning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#le-besoin-de-generaliser">
   Le besoin de généraliser
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definitions">
   Définitions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overfitting">
     Overfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#underfitting">
     Underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalisation-d-un-modele">
     Généralisation d’un modèle
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exemples">
   Exemples
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Underfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Overfitting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generalisation">
     Généralisation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluer-la-generalisation-d-un-modele">
   Évaluer la généralisation d’un modèle
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-test">
     Train/Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#la-recherche-d-hyperparametres">
   La recherche d’hyperparamètres
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-val-test">
     Train/Val/Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#retour-sur-l-exemple-une-bonne-facon-de-faire">
   Retour sur l’exemple : une bonne façon de faire
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#details-supplementaires">
   Détails supplémentaires
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="generalisation-d-un-modele-de-machine-learning">
<h1>Généralisation d’un modèle de Machine Learning<a class="headerlink" href="#generalisation-d-un-modele-de-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>Un des concepts importants lors de l’entraînement d’un modèle est
sa capacité à généraliser.</p>
<p>Nous allons ici voir quels sont les enjeux dont on parle lorsque
l’on parle de généralisation, et comment l’évaluer.</p>
<div class="section" id="le-besoin-de-generaliser">
<h2>Le besoin de généraliser<a class="headerlink" href="#le-besoin-de-generaliser" title="Permalink to this headline">¶</a></h2>
<p>Dans le schéma classique d’un apprentissage supervisé, vous voudrez un modèle capable
de prédire une certaine valeur <span class="math notranslate nohighlight">\(y\)</span> à partir d’un ensemble de valeurs <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Pour qu’un tel modèle soit utile, il faut qu’il soit capable de donner une bonne solution (approximative)
pour des données jamais observées. En effet, à quoi bon utiliser un modèle sur des données où l’on a déjà
collecté et mesuré la valeur de <span class="math notranslate nohighlight">\(y\)</span> !</p>
<p>Pendant l’entraînement d’un modèle, on mesure souvent sa performance sur le jeu de données utilisé pendant l’entraînement.
Cela revient à demander à un étudiant s’il est bien capable de refaire de tête des exercices où on lui a donné
la correction auparavant.
Comment faire pour s’assurer qu’il est capable de réussir la plupart des exercices ?</p>
<p><em>On entend bien ici que l’on veut que l’étudiant réussisse des exercices qui sont bien du même cours que ceux
sur lesquels il s’entraîne. Pour que l’analogie avec un modèle de ML fonctionne, il faudrait donc le soumettre à
de nouvelles données qui sont issues de la même distribution.</em></p>
</div>
<div class="section" id="definitions">
<h2>Définitions<a class="headerlink" href="#definitions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="overfitting">
<h3>Overfitting<a class="headerlink" href="#overfitting" title="Permalink to this headline">¶</a></h3>
<p>L’overfitting, ou sur-apprentissage en français, est le résultat d’un modèle qui a “trop appris”. Il est parfaitement
capable de prédire la bonne solution pour un exemple utilisé pour l’entraîné, mais il devient tout d’un coup très mauvais
lorsqu’on l’évalue sur une toute nouvelle donnée.</p>
<p>Dans le cas de notre étudiant, à force d’entraînement sur les quelques exercices fournis, il aura fini par remarquer
certaines astuces qui permettent de court-circuiter des questions afin d’être plus performant. Mais ces astuces
peuvent se révéler n’être que des coïncidences qui fonctionnent bien sur les quelques exercices mais qui sont en fait fausses.
L’utilisation de ces fausses corrélations s’avère alors dévastateur lors de l’évaluation sur de nouveaux exercices !</p>
<p>On parle alors de sur-entraînement. La machine a détecté des corrélations qui semblent utiles sur le jeu d’entraînement,
mais elles sont en fait de fausses corrélations qui n’expliquent en rien la relation entre <span class="math notranslate nohighlight">\(X\)</span> et <span class="math notranslate nohighlight">\(y\)</span>.
Cela arrive très souvent, et c’est la hantise de toute personne travaillant dans le ML.</p>
</div>
<div class="section" id="underfitting">
<h3>Underfitting<a class="headerlink" href="#underfitting" title="Permalink to this headline">¶</a></h3>
<p>Le sous-apprentissage est ce qui arrive lorsqu’un modèle est en sous-régime.
D’une façon ou d’une autre, le modèle pourrait faire mieux, de manière générale.</p>
<p>Cela revient à un étudiant qui n’a pas réussi à apprendre sur les exercices d’entraînement.
Il n’a peut-être pas assez travaillé (entraînement trop court),
les exercices n’étaient pas assez complets (dataset trop petit),
ou les exercices étaient simplement trop difficiles pour lui (modèle de ML inadapté).</p>
</div>
<div class="section" id="generalisation-d-un-modele">
<h3>Généralisation d’un modèle<a class="headerlink" href="#generalisation-d-un-modele" title="Permalink to this headline">¶</a></h3>
<p>Un modèle généralise bien lorsqu’il performe bien sur des données provenant de
la même distribution que celle utilisée pour l’entraînement.
Cela signifie que sur un exemple jamais rencontré pendant l’entraînement,
le modèle effectue de bonnes prédictions.</p>
<p>Si un modèle généralise bien, c’est qu’<strong>il a appris des corrélations qui
sont utiles</strong>.</p>
<p>Si notre étudiant généralise, c’est que l’entraînement a porté ses fruits
sans avoir sur-appris pour autant.</p>
</div>
</div>
<div class="section" id="exemples">
<h2>Exemples<a class="headerlink" href="#exemples" title="Permalink to this headline">¶</a></h2>
<p>On va prendre un cas simple pour illustrer ce chapitre.
On ne génère que quelques points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">n_points</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/05 - Generalisation_4_0.png" src="../../../_images/05 - Generalisation_4_0.png" />
</div>
</div>
<div class="section" id="id1">
<h3>Underfitting<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Un exemple d’underfitting sur de telles données serait de
réaliser une simple régression linéaire.</p>
<p>Le modèle est trop simple, la relation entre <span class="math notranslate nohighlight">\(X\)</span> et <span class="math notranslate nohighlight">\(y\)</span> est mal
capturée par ce dernier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">r_squared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R² score:&#39;</span><span class="p">,</span> <span class="n">r_squared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/05 - Generalisation_6_0.png" src="../../../_images/05 - Generalisation_6_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R² score: 0.42870723713067405
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Overfitting<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Un moyen d’améliorer le modèle assez facilement est de générer les relations
non-linéaires en amont avant d’entraîner le modèle linéaire.</p>
<p>On peut ainsi générer de nouvelles features, à partir d’interactions polynomiales.
On choisit le degré du polynôme en tant qu’hyperparamètre.
Cependant, il faut être précautionneux dans le choix de cet hyperparamètre.
Il peut facilement mener à un régime d’overfitting. En effet,
il est facile d’interpôler un polynôme sur un certain nombre de point,
Mais le comportement du polynôme en dehors de ces points est ensuite très arbitraire.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">degre_polynome</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="n">X</span> <span class="o">**</span> <span class="n">d</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">degre_polynome</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">])</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">X_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="n">X_range</span> <span class="o">**</span> <span class="n">d</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">degre_polynome</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">])</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_eval</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_range</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">r_squared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R² score:&#39;</span><span class="p">,</span> <span class="n">r_squared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/05 - Generalisation_8_0.png" src="../../../_images/05 - Generalisation_8_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R² score: 1.0
</pre></div>
</div>
</div>
</div>
<p>On peut voir que ce modèle, bien qu’il ait des performances parfaites (<span class="math notranslate nohighlight">\(R^2 = 1\)</span>)
a un mauvais comportement en dehors des points d’entraînement.
Dès qu’on lui demande les valeurs de <span class="math notranslate nohighlight">\(y\)</span> pour des <span class="math notranslate nohighlight">\(X\)</span> qu’il n’a jamais vu lors
de l’entraînement, la réponse est au mieux approximative, et au pire complètement fausse !</p>
</div>
<div class="section" id="generalisation">
<h3>Généralisation<a class="headerlink" href="#generalisation" title="Permalink to this headline">¶</a></h3>
<p>Un meilleur modèle que le précédent est un modèle dont on a bridé
un peu les performances, en lui permettant de n’avoir
accès qu’à des features d’un degré moins élevé.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">degre_polynome</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="n">X</span> <span class="o">**</span> <span class="n">d</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">degre_polynome</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">])</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">X_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_points</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">X_eval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="n">X_range</span> <span class="o">**</span> <span class="n">d</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">degre_polynome</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">])</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_eval</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_range</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">r_squared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Score R² sur entraînement:&#39;</span><span class="p">,</span> <span class="n">r_squared</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/05 - Generalisation_11_0.png" src="../../../_images/05 - Generalisation_11_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Score R² sur entraînement: 0.9137936586866177
</pre></div>
</div>
</div>
</div>
<p>Ici, ce modèle a un comportement qui correspond bien plus au comportement voulu.
Bien qu’il ait un R² plus faible que le précédent sur le jeu d’entraînement,
Il n’a pas sur-appris et effectue des prédictions bien plus justes en dehors des points d’entraînement.</p>
<p>Le meilleur modèle ici est un modèle avec un degré 2, car c’est ainsi qu’ont été générées les données.
Cependant, un tel modèle n’aura jamais un R² à 1, car il y a un bruit intrinsèque dans la génération des données. Ce genre de bruit peut amener
un modèle de ML à faire des corrélations qui sont en fait que des coïncidences.
Réduire la capacité d’un modèle permet d’éviter d’apprendre sur ce bruit et de
se concentrer sur l’essentiel.</p>
<p>Dans le monde réel, le bruit est partout dans nos données et on ne peut
s’en séparer lors de l’entraînement d’un modèle. Il faut faire avec !
Le bruit peut provenir d’une imprécision dans les mesures ou d’un comportement
aléatoire intrinsèque de ce qui est mesuré.</p>
</div>
</div>
<div class="section" id="evaluer-la-generalisation-d-un-modele">
<h2>Évaluer la généralisation d’un modèle<a class="headerlink" href="#evaluer-la-generalisation-d-un-modele" title="Permalink to this headline">¶</a></h2>
<p>On a donc besoin d’évaluer le pouvoir de généralisation de nos modèles.
En fait on peut voir sur les exemples précédents que le meilleur moyen de détecter un mauvais comportement du modèle est de le
tester sur des données qu’il n’a jamais vues auparavant. Le plus simple est donc de diviser les données en deux groupes :</p>
<ul class="simple">
<li><p><strong>Données d’entraînement</strong></p></li>
<li><p><strong>Données de test</strong></p></li>
</ul>
<p>Le premier jeu de données est utilisé pour entraîner le modèle, le second pour évaluer la capacité du modèle à généraliser sur de nouveaux exemples.</p>
<div class="section" id="train-test">
<h3>Train/Test<a class="headerlink" href="#train-test" title="Permalink to this headline">¶</a></h3>
<p>Il est donc tout le temps obligatoire de diviser les données en ces deux catégories. En anglais, on parle de <strong>training dataset</strong> et <strong>testing dataset</strong>.
Le jeu de test doit être représentatif de la distribution des données réelle. En général, on mélange toutes nos données et on en tire au hasard 20%
qui constitueront notre jeu de test.</p>
<p>C’est sur le jeu de test que les performances finales du modèle peuvent être déduites. On n’utilise jamais les métriques sur le jeu d’entraînement
comme métriques finales d’un modèle.</p>
</div>
</div>
<div class="section" id="la-recherche-d-hyperparametres">
<h2>La recherche d’hyperparamètres<a class="headerlink" href="#la-recherche-d-hyperparametres" title="Permalink to this headline">¶</a></h2>
<p><em>Présentation des hyperparamètres ?</em></p>
<p>Vous venez d’entraîner un modèle, vous l’évaluez alors sur le jeu de test et vous observez des performances décevantes. Vous pensez pouvoir
l’améliorer en modifiant quelques hyperparamètres. Ainsi, vous vous mettez à faire plusieurs aller-retours entre l’évaluation du modèle sur le jeu de test
et l’entraînement jusqu’à atteindre ce que vous pensez être les meilleures performances atteignables par le modèle.</p>
<p>Oui mais voilà, à force de régler vos hyperparamètres grâce au jeu de test, vous êtes en train indirectement d’optimiser le modèle sur les données de test.
Cela revient à un étudiant de remarquer petit à petit que certaines techniques fonctionnent particulièrement bien sur le jeu de test. En fait, il est
en train d’overfit sur le jeu de test.</p>
<p>De manière générale, <strong>il faut éviter au maximum de faire fuiter les informations contenues par le jeu de test dans l’entraînement de nos modèles.</strong>
Il faut le garder uniquement pour l’évaluation finale de notre modèle, une fois que l’on a fixé nos hyperparamètres.</p>
<div class="section" id="train-val-test">
<h3>Train/Val/Test<a class="headerlink" href="#train-val-test" title="Permalink to this headline">¶</a></h3>
<p>Alors comment sélectionner nos hyperparamètres ? On utilise un troisième de jeu de données : le <strong>jeu de données de validation</strong>.
C’est avec ce <strong>validation dataset</strong> que vous allez régler (<em>fine-tune</em>) les hyperparamètres de votre modèle.
Ce jeu de données est tiré au hasard parmi vos données de la même façon que vous avez créé votre jeu de test.</p>
<p>En général, voici comment je m’occupe de mes données pour créer les datasets :</p>
<ul class="simple">
<li><p><strong>Données initiales</strong> (<em>100%</em>):</p>
<ul>
<li><p>Données de test (<em>20%</em>)</p></li>
<li><p>Données restantes (<em>80%</em>):</p>
<ul>
<li><p>Données de validation (<em>20%</em>)</p></li>
<li><p>Données d’entraînement (<em>80%</em>)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><em>Diagramme avec des patates est probablement mieux</em></p>
</div>
</div>
<div class="section" id="retour-sur-l-exemple-une-bonne-facon-de-faire">
<h2>Retour sur l’exemple : une bonne façon de faire<a class="headerlink" href="#retour-sur-l-exemple-une-bonne-facon-de-faire" title="Permalink to this headline">¶</a></h2>
<p>On peut revenir sur l’exemple précédent avec nos polynômes en appliquant ce que nous venons de voir pour entraîner un modèle de la bonne façon.</p>
<p>Nous générons 100 points, et nous divisons ces 100 points en les trois groupes d’entraînement, de validation et de test.</p>
<p>Nous évaluons sur le jeu de validation ensuite plusieurs modèles entraînés sur le dataset d’entraînement. Finalement on choisit le meilleur modèle selon
le jeu de validation et on mesure les performances finales sur le jeu de test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_points</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">X</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">X</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_points</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/05 - Generalisation_16_0.png" src="../../../_images/05 - Generalisation_16_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">polynome_features</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">degres</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="n">X</span> <span class="o">**</span> <span class="n">d</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">degres</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">])</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">degres</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LinearRegression</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">polynome_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">degres</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">LinearRegression</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">degres</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">polynome_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">degres</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


<span class="n">degres</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">best_degre</span><span class="p">,</span> <span class="n">best_r_squared</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">degre_polynome</span> <span class="ow">in</span> <span class="n">degres</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">degre_polynome</span><span class="p">)</span>
    <span class="n">r_squared_train</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">degre_polynome</span><span class="p">)</span>
    <span class="n">r_squared_val</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">degre_polynome</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Score du modèle pour le degré </span><span class="si">{</span><span class="n">degre_polynome</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Entraînement : </span><span class="si">{</span><span class="n">r_squared_train</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Validation : </span><span class="si">{</span><span class="n">r_squared_val</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">best_r_squared</span> <span class="o">&lt;</span> <span class="n">r_squared_val</span><span class="p">:</span>
        <span class="n">best_r_squared</span> <span class="o">=</span> <span class="n">r_squared_val</span>
        <span class="n">best_degre</span> <span class="o">=</span> <span class="n">degre_polynome</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Meilleur modèle pour le degré </span><span class="si">{</span><span class="n">best_degre</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">best_degre</span><span class="p">)</span>
<span class="n">r_squared_test</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">best_degre</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Score final sur le jeu de test : </span><span class="si">{</span><span class="n">r_squared_test</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">polynome_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">best_degre</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;real&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pred&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Score du modèle pour le degré 1
Entraînement : 0.830
Validation : 0.658

Score du modèle pour le degré 3
Entraînement : 0.960
Validation : 0.885

Score du modèle pour le degré 5
Entraînement : 0.964
Validation : 0.871

Score du modèle pour le degré 10
Entraînement : 0.966
Validation : 0.875

Score du modèle pour le degré 25
Entraînement : 0.944
Validation : 0.856
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Score du modèle pour le degré 50
Entraînement : 0.777
Validation : -2.964

Meilleur modèle pour le degré 3
Score final sur le jeu de test : 0.948
</pre></div>
</div>
<img alt="../../../_images/05 - Generalisation_17_2.png" src="../../../_images/05 - Generalisation_17_2.png" />
</div>
</div>
<p>On remarque que le degré final est celui théoriquement attendu.
Notre modèle généralise bien.
Il est possible d’aller plus loin en réduisant expressement l’overfitting dans la fonction de loss, cela sera abordé au prochain chapitre !</p>
</div>
<div class="section" id="details-supplementaires">
<h2>Détails supplémentaires<a class="headerlink" href="#details-supplementaires" title="Permalink to this headline">¶</a></h2>
<p>Chaque paramètre doit être entraîné uniquement à l’aide du jeu d’entraînement. Ainsi, même lors du preprocessing de vos données,
vous devez faire en sorte que tout information utilisée doit provenir du jeu d’entraînement uniquement. Par exemple, si vous
décidez de normaliser vos données selon une loi normale, vous devez utiliser la moyenne et l’écart-type du jeu d’entraînement
pour normaliser toutes vos données. Une erreur classique serait d’utiliser la moyenne et l’écart-type de chaque jeu de données pour la normalisation.</p>
<p>Nous avons besoin de nous assurer qu’un modèle généralise bien. Il est toujours possible de trouver des corrélations statistiques
(voir <em><a class="reference external" href="https://tylervigen.com/spurious-correlations">Spurious Correlations</a></em>) dans les données d’entraînement qui semblent expliquer les quelques détails qui améliorent les performances des prédictions.
Or ces petites coïcidences ne permettent pas d’expliquer la relation entre <span class="math notranslate nohighlight">\(X\)</span> et <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>Dans le meilleur des mondes, nous n’aurions pas besoin d’évaluer la généralisation d’un modèle si nous possédions toutes les données possibles et imaginables pour
la tâche considérée. Mais c’est malheureusement impossible (<em>et cela rendrait d’ailleurs le ML beaucoup moins utile</em>), il faut donc s’assurer l’utilité du modèle
une fois hors de l’entraînement.</p>
<p>Enfin, il est intéressant que nous évaluons ici la généralisation d’un modèle sur son domaine de distribution. Sachez qu’il existe
toute une branche de l’IA qui se concentre sur la capacité des modèles à généraliser sur d’autres domaines que celui utilisé pour l’entraînement.
On parle alors de <em><a class="reference external" href="https://out-of-distribution-generalization.com">généralisation out-of-distribution</a></em>.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>La généralisation d’un modèle représente sa capacité à traiter des données jamais vues pendant l’entraînement.</p></li>
<li><p>Un modèle incapable de généraliser est inutile !</p></li>
<li><p>Un moyen de mesurer sa capacité à généraliser est de garder une partie du jeu d’entraînement
comme jeu de test et d’évaluer les performances sur ces données-là.</p></li>
<li><p>Afin d’éviter le sur-apprentissage sur le jeu de test, on utilise un jeu de validation pour régler les hyperparamètres du modèle.
On évalue sur le jeu de test qu’une fois que l’on a la version finale du modèle.</p></li>
</ul>
</div>
<div class="section" id="sources">
<h2>Sources<a class="headerlink" href="#sources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://tylervigen.com/spurious-correlations">Suprious correlations</a></p></li>
<li><p><a class="reference external" href="https://out-of-distribution-generalization.com/">Out-of-distrubution generalization</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/Cours fondamentaux ML/module_1_introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="03%20-%20Regression%20lineaire.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction à la régression : la régression linéaire</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Régularisation &amp; tradeoff biais-variance : une introduction</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Communauté IA-Z<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>