
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Régularisation d’un modèle &#8212; IA-Z</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Compromis biais-variance" href="08%20-%20Compromis%20biais-variance.html" />
    <link rel="prev" title="Régularisation &amp; tradeoff biais-variance : une introduction" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">IA-Z</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../README.html">
   Statut
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage automatique
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="01%20-%20Pourquoi%20le%20ML%20%26%20information%20gr%C3%A2ce%20%C3%A0%20la%20data.html">
   Pourquoi le Machine Learning ?
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="02%20-%20Elements%20de%20definition.html">
     Eléments de définition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03%20-%20Regression%20lineaire.html">
     Introduction à la régression : la régression linéaire
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05%20-%20Generalisation.html">
     Généralisation d’un modèle de Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html">
     Régularisation &amp; tradeoff biais-variance : une introduction
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Régularisation d’un modèle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08%20-%20Compromis%20biais-variance.html">
     Compromis biais-variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11%20-%20Feature%20engineering%20%26%20cleaning.html">
     Feature Engineering
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Traitement automatique de la langue
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/1_Introduction.html">
   Chapitre I: Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/2_DonneesTextuelles.html">
   Etude des données textuelles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/3_ModStatLanguage.html">
   Chapitre II: Notions générales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/4_ModLangues.html">
   Modèles de langues
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/5_Embedings.html">
   Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../NLP/7_bert.html">
   BERT - Bidirectional Encoder Representations from Transformers
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision par ordinateur
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/0_intro.html">
   Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/1_Image_processing.html">
   Section 1 Image processing techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/2_ML_CV.html">
   Machine Learning for Computer Vision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/3_CNN.html">
   Convolutional Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/4_Modern_CNN.html">
   Modern Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours_CV/5_CV_tasks.html">
   Computer Vision tasks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Apprentissage par renforcement
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20RL/1%20-%20Introduction.html">
   Introduction au Reinforcement learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20RL/3%20-%20Processus%20de%20d%C3%A9cision%20markoviens.html">
   Processus de décision markoviens (MDPs)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hors-série
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Cours%20annexes/mener_une_recherche.html">
   Mener une recherche internet efficacement
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/docs/Cours fondamentaux ML/module_1_introduction/07 - Régularisation d'un modèle.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ia-z/ia-z"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ia-z/ia-z/issues/new?title=Issue%20on%20page%20%2Fdocs/Cours fondamentaux ML/module_1_introduction/07 - Régularisation d'un modèle.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ia-z/ia-z/master?urlpath=tree/docs/Cours fondamentaux ML/module_1_introduction/07 - Régularisation d'un modèle.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comment-fonctionne-la-regularisation">
   Comment fonctionne la régularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-exemple">
   Dataset exemple
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation-l2">
   Régularisation L2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exemple">
     Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation-l1">
   Régularisation L1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l1-vs-l2-que-choisir">
   L1 vs L2 : que choisir ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualisation-l1-vs-l2">
     Visualisation L1 vs L2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comment-choisir">
     Comment choisir ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#et-les-autres-regularisations">
   Et les autres régularisations ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Régularisation d’un modèle</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comment-fonctionne-la-regularisation">
   Comment fonctionne la régularisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-exemple">
   Dataset exemple
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation-l2">
   Régularisation L2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exemple">
     Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularisation-l1">
   Régularisation L1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Exemple
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#l1-vs-l2-que-choisir">
   L1 vs L2 : que choisir ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#visualisation-l1-vs-l2">
     Visualisation L1 vs L2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#comment-choisir">
     Comment choisir ?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#et-les-autres-regularisations">
   Et les autres régularisations ?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sources">
   Sources
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="regularisation-d-un-modele">
<h1>Régularisation d’un modèle<a class="headerlink" href="#regularisation-d-un-modele" title="Permalink to this headline">¶</a></h1>
<p>La régularisation est une des méthodes les plus utilisées pour réduire le sur-apprentissage d’un modèle.
Dans ce chapitre, nous allons explorer les régularisations classiques et observer leur impact sur les
performances d’un modèle.</p>
<div class="section" id="comment-fonctionne-la-regularisation">
<h2>Comment fonctionne la régularisation<a class="headerlink" href="#comment-fonctionne-la-regularisation" title="Permalink to this headline">¶</a></h2>
<p>Le principe général est de contraindre les paramètres appris par un modèle.
Pour ce faire, on peut ajouter un terme supplémentaire dans la fonction de loss
que l’on souhaite minimiser.
Ce terme supplémentaire compte comme une pénalité, elle permet de réduire l’overfitting.</p>
<p><em>Mais pourquoi ajouter une pénalité permet de réduire l’overfitting ?</em></p>
<p>Cela peut paraître contre-intuitif, mais en fait réduire les capacités d’apprentissage d’un modèle
peut l’aider à mieux généraliser !
Si on reprend notre exemple du chapitre sur la généralisation, on peut imaginer qu’ajouter une pénalité
à notre modèle revient à l’obliger à travailler avec un kit réduit d’outils à sa disposition.
Il va être obliger de faire avec moins, et donc il ne pourra pas sur-optimiser son apprentissage sur
les exercices d’entraînement (les petites corrélations qui améliorent marginalement les performances
mais qui se trouvent inutiles voire désastreuses lors de l’évaluation sur de nouveaux exercices).</p>
<p>D’une certaine manière, ajouter une pénalité sur les paramètres du modèle revient à demander au modèle
de trouver une solution simple et efficace au problème donné. Cette solution est
<a class="reference external" href="https://fr.wikipedia.org/wiki/Rasoir_d%27Ockham">généralement la meilleure</a> !</p>
<p>Nous allons voir particulièrement deux façons de régulariser un modèle : la régularisation L1 et L2.
Nous les verrons appliquées à la regression linéaire, mais il faut savoir que ces méthodes sont générales et s’appliquent
à tout type de modèle paramétrique.</p>
</div>
<div class="section" id="dataset-exemple">
<h2>Dataset exemple<a class="headerlink" href="#dataset-exemple" title="Permalink to this headline">¶</a></h2>
<p>Afin de mieux se rendre compte de l’impact de la régularisation sur nos modèles, nous utilisons un dataset fictif.
Pour simplifier la lecture, nous n’utilisons pas de jeu de validation ici, car nous choisissons d’uniquement comparer
les performances finales de généralisation de nos modèles sans faire de recherche d’hyperparamètre.
Cependant, gardez en tête qu’en cas réel, il faut aussi générer le jeu de validation et n’évaluer qu’un modèle final
sur le jeu de test.</p>
<p>Le dataset est généré en ajoutant un fort bruit pour empêcher nos modèles linéaires de pouvoir prédire parfaitement <code class="docutils literal notranslate"><span class="pre">y</span></code>.
Cela permet de faciliter l’overfitting de nos modèles si nous ne sommes pas prudent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
    <span class="n">noise</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="regularisation-l2">
<h2>Régularisation L2<a class="headerlink" href="#regularisation-l2" title="Permalink to this headline">¶</a></h2>
<p>La régularisation L2 demande à ce que la somme des carrés des paramètres soit la plus petite possible.
C’est une fonction quadratique, elle est donc continue et dérivable en tout point ce qui est souvent apprécié.</p>
<p>Mathématiquement on peut écrire :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\text{L2}(w) &amp; = \sum_i w_i^2\\
\text{loss}_{\text{final}}(w) &amp; = \text{loss}(w) + \lambda \text{L2}(w)
\end{align}\end{split}\]</div>
<p>Afin de moduler la force de pénalisation par rapport à la loss initiale, on définit un hyperparamètre <span class="math notranslate nohighlight">\(\lambda\)</span> qui est une constante positive
choisie avant l’entraînement. Un <span class="math notranslate nohighlight">\(\lambda\)</span> trop gros empêchera le modèle d’apprendre (il ne pourra plus s’exprimer
car la moindre modification de ses poids sera fortement pénalisée), mais un <span class="math notranslate nohighlight">\(\lambda\)</span> trop faible masquera l’effet
de la régularisation.</p>
<p>Cette régularisation (ainsi que la L1 juste après) pousse le modèle à apprendre des coefficients pas trop éloignés de 0.
Il doit équilibrer son entraînement afin de réduire la loss principale et éviter d’avoir une pénalité élevée.
Intuitivement, le modèle est contraint à simplifier sa prédiction.
Il ne peut pas affiner ses prédictions, ce qui le rend moins précis sur le jeu d’entraînement
mais qui réduit la chance de sur-apprentissage.</p>
<p>On parle de <em>Ridge Regression</em> lorsque l’on fait une régression linéaire couplée à une régularisation L2.</p>
<div class="section" id="exemple">
<h3>Exemple<a class="headerlink" href="#exemple" title="Permalink to this headline">¶</a></h3>
<p>Dans <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, le modèle permettant de faire une régression linéaire avec régularisation L2 se nomme <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="k">def</span> <span class="nf">train_ridge</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Ridge regression avec une valeur de lambda = </span><span class="si">{</span><span class="n">lambda_value</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">coefs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;L2(w) = </span><span class="si">{</span><span class="p">(</span><span class="n">coefs</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">r2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² sur le jeu d&#39;entraînement: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">r2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² sur le jeu de test: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">train_ridge</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">train_ridge</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge regression avec une valeur de lambda = 0
L2(w) = 49709.83
R² sur le jeu d&#39;entraînement: 1.000
R² sur le jeu de test: 0.476

Ridge regression avec une valeur de lambda = 1
L2(w) = 15137.40
R² sur le jeu d&#39;entraînement: 0.972
R² sur le jeu de test: 0.786
</pre></div>
</div>
</div>
</div>
<p>Le modèle sans régularisation (<span class="math notranslate nohighlight">\(\lambda = 0\)</span>) a sur-appris par rapport au second modèle !
On s’aperçoit que c’est bien le modèle ayant la pénalité <span class="math notranslate nohighlight">\(\text{L2}(w)\)</span> la plus faible qui généralise mieux.</p>
</div>
</div>
<div class="section" id="regularisation-l1">
<h2>Régularisation L1<a class="headerlink" href="#regularisation-l1" title="Permalink to this headline">¶</a></h2>
<p>La régularisation L1 contraint la norme L1 des paramètres à être la plus petite possible.
Elle n’est pas dérivable en 0, mais ce n’est pas gênant en pratique.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\text{L1}(w) &amp; = \sum_i |w_i| \\
\text{loss}_{\text{final}}(w) &amp; = \text{loss}(w) + \lambda \text{L1}(w)
\end{align}\end{split}\]</div>
<p>Cette régularisation a tendance à pousser des coefficients <span class="math notranslate nohighlight">\(w\)</span> à valoir 0 exactement, ce qui est utile
pour faire de la sélection de features. En effet, si une feature a un coefficient associé qui
vaut exactement 0, alors on peut se débarasser de cette feature car elle n’influe clairement pas le calcul des prédictions !</p>
<p>On parle de <em>Lasso Regression</em> lorsque l’on fait une régression linéaire couplée à une régularisation L1.</p>
<div class="section" id="id1">
<h3>Exemple<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">LinearRegression</span>

<span class="k">def</span> <span class="nf">train_lasso</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;LASSO regression avec une valeur de lambda = </span><span class="si">{</span><span class="n">lambda_value</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lambda_value</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Problème de convergence du LASSO lorsque lambda = 0</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">coefs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;L2(w) = </span><span class="si">{</span><span class="p">(</span><span class="n">coefs</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Coefs nuls: </span><span class="si">{</span><span class="p">(</span><span class="n">coefs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">r2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² sur le jeu d&#39;entraînement: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">r2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R² sur le jeu de test: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">train_lasso</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">train_lasso</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LASSO regression avec une valeur de lambda = 0
L2(w) = 49709.83
Coefs nuls: 0
R² sur le jeu d&#39;entraînement: 1.000
R² sur le jeu de test: 0.476

LASSO regression avec une valeur de lambda = 3
L2(w) = 18262.30
Coefs nuls: 2
R² sur le jeu d&#39;entraînement: 0.981
R² sur le jeu de test: 0.816
</pre></div>
</div>
</div>
</div>
<p>Comme pour l’exemple précédent, le modèle qui généralise le mieux est celui qui est régularisé.
On remarque de plus que le modèle régularisé a décidé que deux des features étaient inintéressantes pour la prédiction.
C’est cohérent car nous avons généré le dataset à l’aide de 7 features informatives parmis 10 features au total
(il y a donc 3 features qui ne servent pas à la prédiction, et qui sont présentes uniquement pour brouiller le modèle).</p>
</div>
</div>
<div class="section" id="l1-vs-l2-que-choisir">
<h2>L1 vs L2 : que choisir ?<a class="headerlink" href="#l1-vs-l2-que-choisir" title="Permalink to this headline">¶</a></h2>
<p>Nous connaissons maitenant deux méthodes qui permettent de régulariser facilement un modèle.</p>
<p><em>Comment choisir entre les deux ? Laquelle est la meilleure ?</em></p>
<p>Pour mieux comprendre la différence entre les deux méthodes on peut visualiser les solutions engendrées par l’utilisation
de l’une ou l’autre façon de régulariser.</p>
<div class="section" id="visualisation-l1-vs-l2">
<h3>Visualisation L1 vs L2<a class="headerlink" href="#visualisation-l1-vs-l2" title="Permalink to this headline">¶</a></h3>
<p>Pour mieux visualiser leur effet sur l’entraînement de nos modèles, nous pouvons considérer un cas simple où nous
avons deux paramètres <span class="math notranslate nohighlight">\(w_1\)</span> et <span class="math notranslate nohighlight">\(w_2\)</span> à entraîner. On peut reformuler les problèmes de minimisation comme des problèmes
de minimisation sous contraintes :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\arg \min_{w_1, w_2} \text{loss}(w_1, w_2) + \lambda (|w_1| + |w_2|)
&amp; \iff \arg \min_{|w_1| + |w_2| \leq \beta} \text{loss}(w_1, w_2) \\
\arg \min_{w_1, w_2} \text{loss}(w_1, w_2) + \lambda (w_1^2 + w_2^2)
&amp; \iff \arg \min_{w_1^2 + w_2^2 \leq \beta} \text{loss}(w_1, w_2)
\end{align}\end{split}\]</div>
<p>Ces deux façons de voir le problème sont équivalentes. <span class="math notranslate nohighlight">\(\beta\)</span> est inversement proportionnel à <span class="math notranslate nohighlight">\(\lambda\)</span>.
On peut ainsi tracer les courbes de niveaux du loss en fonction des valeurs de <span class="math notranslate nohighlight">\(w_1\)</span> et <span class="math notranslate nohighlight">\(w_2\)</span> et visualiser
les zones où les contraintes sont satisfaites (l’espace des solutions réalisables).</p>
<div class="figure align-default" id="l1vsl2-fig">
<img alt="L1vsL2" src="../../../_images/L1vsL2.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Visualisation de la régularisation L1 (à gauche) et L2 (à droite).</span><a class="headerlink" href="#l1vsl2-fig" title="Permalink to this image">¶</a></p>
</div>
<p>Comme on peut le voir, la régularisation L1 impose des solutions dans un espace en forme de diamant, alors
que la L2 génère un espace de solutions en forme de cercle.
La solution optimale sans régularisation est représentée par le point <span class="math notranslate nohighlight">\(w^*\)</span>.
Le loss ici est une simple <em>MSE</em>, dont les courbes de niveaux tracent des ellipses de plus en plus grandes autour du minimum <span class="math notranslate nohighlight">\(w^*\)</span>.
La solution obtenue avec régularisation est représentée par le point <span class="math notranslate nohighlight">\(\hat w\)</span>.</p>
<p><em>Visuellement, la solution optimale <span class="math notranslate nohighlight">\(\hat w\)</span> est à la jonction
entre les courbes de niveau du loss et la frontière de l’espace des solutions.</em></p>
<p>Ainsi, il est aisé de comprendre pourquoi la régularisation L1 pousse plus facilement les coefficients <span class="math notranslate nohighlight">\(\hat w\)</span> vers 0.
En prenant un point <span class="math notranslate nohighlight">\(w^*\)</span> au hasard sur le plan 2D, il est plus probable que la projection des courbes de niveaux sur le
diamant arrive sur un des angles !</p>
</div>
<div class="section" id="comment-choisir">
<h3>Comment choisir ?<a class="headerlink" href="#comment-choisir" title="Permalink to this headline">¶</a></h3>
<p>En pratique, les deux méthodes peuvent donner de meilleurs résultats. Dans notre exemple, c’est la normalisation L1 qui s’en sort le mieux (puisque son <span class="math notranslate nohighlight">\(R^2\)</span> est plus élevé sur le jeu de test), mais ça pourrait très bien être l’inverse !
Le mieux est de tester les deux méthodes et de comparer les performances des modèles sur le jeu de validation.</p>
<p>Rien n’empêche d’utiliser à la fois la régularisation L1 et L2. Lorsque les deux méthodes sont utilisées pour une
régression linéaire, on dit que l’on utilise une méthode <em>Elastic Net</em>. En pratique, c’est <em>Elastic Net</em> qui a tendance à donner
de meilleurs résultats que la L1 ou la L2 pris séparéments.</p>
<p>Les deux méthodes ont quand même chacune leur avantage :</p>
<ul class="simple">
<li><p>L2 est dérivable en tout point, ce qui peut aider pour certains algorithmes d’optimisation.</p></li>
<li><p>L1 permet de sélectionner les features utiles pour la prédiction.</p></li>
</ul>
<p>Parce que la L2 est dérivable partout, elle est généralement préférée. Elle permet de ne pas se soucier du cas particulier
où la dérivée n’est pas définie. Cependant, sachez en pratique ne pas être dérivable en un unique point est rarement dérangeant.</p>
</div>
</div>
<div class="section" id="et-les-autres-regularisations">
<h2>Et les autres régularisations ?<a class="headerlink" href="#et-les-autres-regularisations" title="Permalink to this headline">¶</a></h2>
<p>Il est possible de régulariser le modèle de plusieurs façons possibles. Les autres façons de régulariser
dépendent beaucoup du modèle et de la tâche qui sont considérés.</p>
<p>Par exemple dans le chapitre sur la généralisation, nous avons régularisé nos régressions polynomiales sans même le savoir.
En effet, on a contraint les capacités du modèle en choisissant de limiter le degré maximal de notre polynôme !
(<em>Peut-on vraiment parler de régularisation pour ce cas là ?</em>)</p>
<p>D’autres régularisations existent donc. Elles sont souvent spécifiques au type de modèle choisi, et se découvrent
donc petit à petit en même temps que l’on apprend à utiliser d’autres modèles.
La L1 et L2 sont quand même les deux régularisations les plus utilisées et il est important de les connaître.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>La régularisation est une technique permettant de réduire l’overfitting des modèles de ML.</p></li>
<li><p>En général, le but d’une régularisation est de réduire la complexité du modèle.
Elle s’exprime sous forme de pénalité ajoutée à la loss du modèle.</p></li>
<li><p>Les deux méthodes de régularisation les plus utilisées sont la L1 et L2.
Elles poussent toutes les deux les coefficients des modèles vers 0.</p></li>
</ul>
</div>
<div class="section" id="sources">
<h2>Sources<a class="headerlink" href="#sources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data, Gilbert Strang, 2019</a></p></li>
<li><p><a class="reference external" href="https://explained.ai/regularization/L1vsL2.html">L1 vs L2, Terence Parr</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/Cours fondamentaux ML/module_1_introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="06%20-%20R%C3%A9gularisation%20%26%20tradeoff%20biais-variance%20-%20une%20introduction.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Régularisation &amp; tradeoff biais-variance : une introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="08%20-%20Compromis%20biais-variance.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compromis biais-variance</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Communauté IA-Z<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>